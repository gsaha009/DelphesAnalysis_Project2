{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfae5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import random\n",
    "import string\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import root_pandas as rpd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn')\n",
    "plt.style.use('ggplot')\n",
    "from collections import defaultdict\n",
    "import ROOT\n",
    "import copy\n",
    "import tensorflow.keras\n",
    "import tensorflow.saved_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from tensorflow.keras.utils.vis_utils import plot_model                                                                                                                \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c78825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lumi : 300000 pb-1\n"
     ]
    }
   ],
   "source": [
    "with open('config.yaml','r') as conf:\n",
    "    config = yaml.safe_load(conf)\n",
    "mainkeys    = list(config.keys())\n",
    "tag         = config.get('Tag')\n",
    "pwd         = os.getcwd()\n",
    "tagdir      = os.path.join(pwd,tag)\n",
    "\n",
    "maintree    = config.get('intree')\n",
    "infiledict  = config.get('infiles')\n",
    "lumi = config.get('Lumi')\n",
    "print(f'Lumi : {lumi} pb-1')\n",
    "usenorm     = config.get('UseNormForPlots')\n",
    "scale       = config.get('DoScaling')\n",
    "#print(infiledict)\n",
    "clskeys = list(infiledict.keys())\n",
    "#print(clskeys)\n",
    "featuredict = config.get('features') \n",
    "featurelist = list(featuredict.keys())\n",
    "lbnfeaturelist = config.get('lbnfeatures')\n",
    "signaldict = infiledict.get('Signal')\n",
    "backgrounddict = infiledict.get('Background')\n",
    "restbackgrounddict = infiledict.get('RestBackground')\n",
    "\n",
    "dfs_dict = dict()\n",
    "for key, val in signaldict.items():\n",
    "    df_item = rpd.read_root(val[0], key=maintree)[featurelist+lbnfeaturelist]\n",
    "    df_item['tag'] = 1\n",
    "    xsec = val[1]\n",
    "    nEvents = val[2]\n",
    "    label = val[3]\n",
    "    dfs_dict[key] = [df_item, xsec, nEvents, label]\n",
    "\n",
    "for key, val in backgrounddict.items():\n",
    "    df_item = rpd.read_root(val[0], key=maintree)[featurelist+lbnfeaturelist]\n",
    "    df_item['tag'] = 0\n",
    "    xsec = val[1]\n",
    "    nEvents = val[2]\n",
    "    label = val[3]\n",
    "    dfs_dict[key] = [df_item, xsec, nEvents, label]\n",
    "\n",
    "for key, val in restbackgrounddict.items():\n",
    "    df_item = rpd.read_root(val[0], key=maintree)[featurelist+lbnfeaturelist]\n",
    "    df_item['tag'] = 0\n",
    "    xsec = val[1]\n",
    "    nEvents = val[2]\n",
    "    label = val[3]\n",
    "    dfs_dict[key] = [df_item, xsec, nEvents, label]\n",
    "    \n",
    "#dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad5eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file  = open(os.path.join(tagdir,\"DNN_model.json\"), 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# load weights into new model                                                                                                                             \n",
    "model.load_weights(os.path.join(tagdir,\"DNN_model.h5\"))\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a76ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 6, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 6, 4), dtype=tf.float32, name='LBN_inputs'), name='LBN_inputs', description=\"created by layer 'LBN_inputs'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    }
   ],
   "source": [
    "labelhistdict = {}\n",
    "labelhistdictforplot = defaultdict(list)\n",
    "nbins = 50\n",
    "xmin  = 0.0\n",
    "xmax  = 1.0\n",
    "scale = False\n",
    "for sample, info in dfs_dict.items():\n",
    "    #print(sample, info[3])\n",
    "    pdtonp = info[0].to_numpy()\n",
    "    #print(pdtonp.shape)\n",
    "    X_np = pdtonp[:,:pdtonp.shape[1]-1]\n",
    "    X_test_scaled = scaler.transform(X_np) if scale else X_np\n",
    "    #print(X_np.shape)\n",
    "    Y_np = pdtonp[:,-1]\n",
    "    #print(Y_np.shape)\n",
    "    x_test_lbn = X_test_scaled[:,-len(lbnfeaturelist):].reshape(-1,len(lbnfeaturelist)//4,4)\n",
    "    fit_test = np.hsplit(X_test_scaled,X_test_scaled.shape[1])\n",
    "    fit_test.append(x_test_lbn)\n",
    "    scores    = model.predict(fit_test)\n",
    "    #print(f'{sample} : {scores}')\n",
    "    hname = 'pred_hist_'+sample\n",
    "    hname = ROOT.TH1F(hname, \"\", nbins, xmin, xmax)\n",
    "    preds = list(scores[:,-1]) if sample == 'muta_lnu' else list(scores[:,1])\n",
    "    for item in preds:\n",
    "        hname.Fill(item)\n",
    "    #print(f'sample : {sample}, nRawEvents : {hname.Integral()}')\n",
    "    hname.Scale(info[1]*lumi/info[2])\n",
    "    #print(f' -- nLumiScaledEvents : {hname.Integral()}')\n",
    "    labelhistdict[sample] = hname # for individual process \n",
    "    labelhistdictforplot[info[3]].append(hname)\n",
    "    hname.SetDirectory(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "signifs = []\n",
    "bdtscores = []\n",
    "hsig = labelhistdict.get('muta_lnu')\n",
    "for i in range(nbins):\n",
    "    ibin = i+1\n",
    "    #print(f'bin > {ibin}')\n",
    "    nsig = hsig.Integral(ibin, nbins)\n",
    "    #print(f'nSignal : {nsig}')\n",
    "    nbkg = 0\n",
    "    #print('Bkg -->')\n",
    "    for j,(key, val) in enumerate(labelhistdict.items()):\n",
    "        if j == 0 : \n",
    "            continue\n",
    "        nbkg_ = val.Integral(ibin, nbins)\n",
    "        #print(f' >>--- proc : {key} --> {nbkg_}')\n",
    "        nbkg += nbkg_\n",
    "    if nsig+nbkg == 0:\n",
    "        continue\n",
    "    signif = nsig/sqrt(nsig+nbkg)\n",
    "    #print(f'total Bkg. {nbkg}')\n",
    "    #print(f'BDT score : {hsig.GetBinCenter(ibin)} , Significance. {signif}\\n')\n",
    "    bdtscores.append(round(hsig.GetBinCenter(ibin),3))\n",
    "    signifs.append(round(signif,3))\n",
    "\n",
    "#print(signifs, len(signifs))   \n",
    "#print(bdtscores, len(bdtscores))\n",
    "\n",
    "plt.figure(figsize=(12,8.5))\n",
    "plt.plot(bdtscores, signifs, lw=3)\n",
    "plt.xlabel('DNN score', size=20)\n",
    "plt.ylabel('Significance', size=20)\n",
    "plt.title('s/sqrt(s+b) vs. DNN score', size=20)\n",
    "plt.text(0.2, 1.5, f'max significance : {max(signifs)}\\n at BDT_score : {bdtscores[signifs.index(max(signifs))]}', fontsize = 22)\n",
    "plt.savefig(os.path.join(tagdir,'maxSignificance.png'),dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4759c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
